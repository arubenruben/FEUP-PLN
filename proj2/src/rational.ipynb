{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule\n",
    "from datasets import Dataset\n",
    "from datasets import DatasetDict\n",
    "from datasets import load_metric\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_LABELS = 5\n",
    "\n",
    "model_name = \"neuralmind/bert-base-portuguese-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENCODING = {\"label\": {\"Value\": 0, \"Value(+)\": 1, \"Value(-)\": 2, \"Fact\": 3, \"Policy\": 4}}\n",
    "\n",
    "\n",
    "def create_index_column(df):\n",
    "    df[\"id\"] = df.index + 1\n",
    "\n",
    "def load_dataset():\n",
    "    \n",
    "    df_text = pd.DataFrame(pd.read_excel(os.path.join('./dataset', 'OpArticles.ods')))\n",
    "\n",
    "    df_adu = pd.DataFrame(\n",
    "        pd.read_excel(os.path.join('./dataset', 'aug.ods')))\n",
    "    \n",
    "    create_index_column(df_adu)\n",
    "    \n",
    "    return df_adu, df_text\n",
    "\n",
    "\n",
    "\n",
    "def remove_dataframe_rows_by_id(df_to_remove, list_ids_to_remove):\n",
    "    df_to_remove.set_index(\"id\", inplace=True)\n",
    "\n",
    "    df_to_remove.drop(list_ids_to_remove, inplace=True)\n",
    "\n",
    "    df_to_remove.reset_index(inplace=True)\n",
    "\n",
    "\n",
    "def split_train_test(df):\n",
    "    \n",
    "    train, test = train_test_split(df, test_size=0.3, random_state=42, stratify=df['label'])\n",
    "    \n",
    "    \n",
    "    val, test = train_test_split(test, test_size=0.3, random_state=42, stratify=test['label'])\n",
    "\n",
    "    train = pd.DataFrame.from_dict(train)\n",
    "    \n",
    "    val = pd.DataFrame.from_dict(val)\n",
    "    \n",
    "    test = pd.DataFrame.from_dict(test)\n",
    "    \n",
    "    return train, val, test\n",
    "    \n",
    "def outlier_detection(df_adu):\n",
    "    results = {}\n",
    "    dict_collisions = {}\n",
    "    for _, row in df_adu.iterrows():\n",
    "        if row['article_id'] not in results.keys():\n",
    "            results[row['article_id']] = {\n",
    "                'A': [],\n",
    "                'B': [],\n",
    "                'C': [],\n",
    "                'D': []\n",
    "            }\n",
    "\n",
    "        if row['annotator'] == 'A':\n",
    "            results[row['article_id']]['A'].append({\n",
    "                'id': row['id'],\n",
    "                'ranges': row['ranges'],\n",
    "                'tokens': row['tokens'],\n",
    "                'label': row['label']\n",
    "            })\n",
    "\n",
    "        elif row['annotator'] == 'B':\n",
    "            results[row['article_id']]['B'].append({\n",
    "                'id': row['id'],\n",
    "                'ranges': row['ranges'],\n",
    "                'tokens': row['tokens'],\n",
    "                'label': row['label']\n",
    "            })\n",
    "\n",
    "        elif row['annotator'] == 'C':\n",
    "            results[row['article_id']]['C'].append({\n",
    "                'id': row['id'],\n",
    "                'ranges': row['ranges'],\n",
    "                'tokens': row['tokens'],\n",
    "                'label': row['label']\n",
    "            })\n",
    "\n",
    "        elif row['annotator'] == 'D':\n",
    "            results[row['article_id']]['D'].append({\n",
    "                'id': row['id'],\n",
    "                'ranges': row['ranges'],\n",
    "                'tokens': row['tokens'],\n",
    "                'label': row['label']\n",
    "            })\n",
    "\n",
    "    for article_id in results.keys():\n",
    "\n",
    "        for adu_A in results[article_id]['A']:\n",
    "            adu_matching(adu_A, results[article_id]['B'], results[article_id]['C'], results[article_id]['D'],\n",
    "                         dict_collisions)\n",
    "        for adu_B in results[article_id]['B']:\n",
    "            adu_matching(adu_B, results[article_id]['A'], results[article_id]['C'], results[article_id]['D'],\n",
    "                         dict_collisions)\n",
    "        for adu_C in results[article_id]['C']:\n",
    "            adu_matching(adu_C, results[article_id]['A'], results[article_id]['B'], results[article_id]['D'],\n",
    "                         dict_collisions)\n",
    "        for adu_D in results[article_id]['D']:\n",
    "            adu_matching(adu_D, results[article_id]['A'], results[article_id]['B'], results[article_id]['C'],\n",
    "                         dict_collisions)\n",
    "\n",
    "    return dict_collisions\n",
    "\n",
    "\n",
    "def adu_matching(adu, list_annotater_X, list_annotater_Y, list_annotater_Z, dict_collisions):\n",
    "    for iterator in [list_annotater_X, list_annotater_Y, list_annotater_Z]:\n",
    "        for elem in iterator:\n",
    "            if json.loads(adu['ranges'])[0][0] < json.loads(elem['ranges'])[0][0] < json.loads(adu['ranges'])[0][1]:\n",
    "                if adu['label'] != elem['label']:\n",
    "                    # print(f\"Disagreement between:\\n{adu['tokens']} \\n and \\n {elem['tokens']}\")\n",
    "                    if adu['id'] not in dict_collisions.keys():\n",
    "                        dict_collisions[adu['id']] = [elem['id']]\n",
    "                    else:\n",
    "                        dict_collisions[adu['id']].append(elem['id'])\n",
    "\n",
    "\n",
    "def deal_with_outliers(df_adu, dict_collisions, option='delete'):\n",
    "    # print(f\"Before:{df_adu.describe()}\")\n",
    "\n",
    "    if option == 'delete':\n",
    "        list_to_remove = []\n",
    "\n",
    "        for key_left in dict_collisions.keys():\n",
    "            list_to_remove.append(key_left)\n",
    "            for elem in dict_collisions[key_left]:\n",
    "                list_to_remove.append(elem)\n",
    "\n",
    "        remove_dataframe_rows_by_id(df_adu, list_to_remove)\n",
    "\n",
    "    elif option == 'majority':\n",
    "        list_to_remove = []\n",
    "        for key_left in dict_collisions.keys():\n",
    "            counters = {\n",
    "                'Fact': 0,\n",
    "                'Policy': 0,\n",
    "                'Value': 0,\n",
    "                'Value(+)': 0,\n",
    "                'Value(-)': 0,\n",
    "            }\n",
    "\n",
    "            majority_vote = None\n",
    "            number_votes = 0\n",
    "\n",
    "            adu = df_adu.loc[df_adu['id'] == key_left].iloc[0]\n",
    "\n",
    "            counters[adu['label']] += 1\n",
    "\n",
    "            for elem in dict_collisions[key_left]:\n",
    "                adu = df_adu.loc[df_adu['id'] == elem].iloc[0]\n",
    "                counters[adu['label']] += 1\n",
    "\n",
    "            for elem in counters.keys():\n",
    "                number_votes += counters[elem]\n",
    "\n",
    "            \"\"\"\n",
    "            Find the majority vote type\n",
    "            Majority_Vote returns a Valid Label\n",
    "            \"\"\"\n",
    "\n",
    "            for elem in counters.keys():\n",
    "                if counters[elem] / number_votes >= 0.5:\n",
    "                    majority_vote = elem\n",
    "                    break\n",
    "\n",
    "            if not majority_vote:\n",
    "                continue\n",
    "\n",
    "            if adu['label'] != majority_vote:\n",
    "                list_to_remove.append(adu['id'])\n",
    "\n",
    "            for elem in dict_collisions[key_left]:\n",
    "                elem_adu = df_adu.loc[df_adu['id'] == elem].iloc[0]\n",
    "                if elem_adu['label'] != majority_vote:\n",
    "                    list_to_remove.append(elem_adu['id'])\n",
    "\n",
    "        remove_dataframe_rows_by_id(df_adu, list_to_remove)\n",
    "\n",
    "    # print(f\"After:{df_adu.describe()}\")\n",
    "#ENCODING = {\"label\": {\"Value\": 0, \"Value(+)\": 1, \"Value(-)\": 2, \"Fact\": 3, \"Policy\": 4}}   \n",
    "def augment_train(df_train):\n",
    "    new_lines={\n",
    "        'tokens':[],\n",
    "        'label':[],\n",
    "    }\n",
    "    for _, row in df_train.iterrows():\n",
    "        #if row['label'] == 1 or row['label'] == 4:\n",
    "        if row['label'] == 4 :\n",
    "            correct_str = row['augmented']\n",
    "            \n",
    "            en_str = row['en']\n",
    "            sp_str = row['sp']\n",
    "            \n",
    "            if not row['tokens'][0].isupper():\n",
    "                correct_str = correct_str[0].lower() + correct_str[1:]\n",
    "                en_str = en_str[0].lower() + en_str[1:]\n",
    "                sp_str = sp_str[0].lower() + sp_str[1:]\n",
    "                        \n",
    "            new_lines['tokens'].append(correct_str)\n",
    "            new_lines['label'].append(row['label'])\n",
    "            #new_lines['tokens'].append(en_str)\n",
    "            #new_lines['label'].append(row['label'])\n",
    "            #new_lines['tokens'].append(sp_str)\n",
    "            #new_lines['label'].append(row['label'])\n",
    "        \n",
    "    df = pd.DataFrame(new_lines)\n",
    "    \n",
    "    return df_train.append(df, ignore_index = True)\n",
    "\n",
    "def clean_duplicates(df_adu):\n",
    "    print(f\"Before: {len(df_adu)}\")\n",
    "    \n",
    "    new_lines={\n",
    "        'tokens':[],\n",
    "        'label':[],\n",
    "    }\n",
    "    \n",
    "    for index, row in df_adu.iterrows():\n",
    "        \n",
    "        if len(df_adu[df_adu['tokens']==row['tokens']])==1:\n",
    "            new_lines['tokens'].append(row['tokens'])\n",
    "            new_lines['label'].append(row['label'])\n",
    "        elif row['label'] != 0:\n",
    "            if row['tokens'] not in new_lines['tokens']:\n",
    "                new_lines['tokens'].append(row['tokens'])\n",
    "                new_lines['label'].append(row['label'])\n",
    "    \n",
    "    \n",
    "    df_adu = pd.DataFrame(new_lines)   \n",
    "    \n",
    "    print(f\"After: {len(df_adu)}\")\n",
    "    \n",
    "    return df_adu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"tokens\"], padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adu, _ = load_dataset()\n",
    "\n",
    "train, val, test = split_train_test(df_adu)\n",
    "\n",
    "dict_collisions = outlier_detection(train)\n",
    "\n",
    "deal_with_outliers(train, dict_collisions, 'delete')\n",
    "\n",
    "train.drop(columns=['article_id', 'annotator', 'node', 'ranges', 'id'], inplace = True)\n",
    "train.replace(ENCODING, inplace=True)\n",
    "train.reset_index(drop=True, inplace=True)\n",
    "\n",
    "val.drop(columns=['article_id', 'annotator', 'node', 'ranges', 'id', 'sp', 'augmented', 'en'], inplace = True)\n",
    "val.replace(ENCODING, inplace=True)\n",
    "val.reset_index(drop=True, inplace=True)\n",
    "\n",
    "test.drop(columns=['article_id', 'annotator', 'node', 'ranges', 'id', 'sp', 'augmented', 'en'], inplace = True)\n",
    "test.replace(ENCODING, inplace=True)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = augment_train(train)\n",
    "\n",
    "train.drop(columns=['sp', 'augmented', 'en'], inplace = True)\n",
    "\n",
    "#train = clean_duplicates(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at neuralmind/bert-base-portuguese-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at neuralmind/bert-base-portuguese-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb8cc00b0714ce78d88c301f01dcda4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb694d8b96e047eeafc77ed08b1e677e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7706adf12bba408b93bd077b952949b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_valid_test_dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train),\n",
    "    'validation': Dataset.from_pandas(val),\n",
    "    'test': Dataset.from_pandas(test)\n",
    "})\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, do_lower_case=False)\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels = NUM_LABELS)\n",
    "\n",
    "tokenized_dataset = train_valid_test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "max_layer = 11\n",
    "#max_layer = 24\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    for elem in range(max_layer-5):\n",
    "        if name.startswith(f\"bert.encoder.layer.{elem}.\"): # choose whatever you like here\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.42225627 2.51379704 1.20010887 0.98244207 2.61208531]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:72: FutureWarning: Pass classes=[0 1 2 3 4], y=[3 2 0 ... 4 4 4] as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  \"will result in an error\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "weights = compute_class_weight('balanced', np.unique(train['label']),np.array(train['label']))\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/setuptools/distutils_patch.py:26: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.\n",
      "  \"Distutils was imported before Setuptools. This usage is discouraged \"\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "#ENCODING = {\"label\": {\"Value\": 0, \"Value(+)\": 1, \"Value(-)\": 2, \"Fact\": 3, \"Policy\": 4}}\n",
    "from torch import nn\n",
    "from transformers import Trainer\n",
    "\n",
    "\n",
    "class CustomTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        # forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        # compute custom loss\n",
    "        #loss_fct = nn.CrossEntropyLoss()\n",
    "        #loss_fct = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([0.144841791087912, 0.36597554029858, 0.19756812689478, 0.1785916532763, 0.41302288844243]))\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([0.044841791087912, 0.36597554029858, 0.09756812689478, 0.0785916532763, 0.41302288844243]))\n",
    "        #loss_fct = nn.CrossEntropyLoss(weight=torch.cuda.FloatTensor([0.0083380112344987, 0.062851882499246, 0.017616001354013, 0.014306433866884, 0.89688767104536]))\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    metric = load_metric(\"f1\")\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    f1_val = metric.compute(predictions=predictions, references=labels, average='macro')\n",
    "\n",
    "    metric = load_metric(\"accuracy\")\n",
    "    acc_val = metric.compute(predictions=predictions, references=labels)\n",
    "\n",
    "    return {\n",
    "        'f1':f1_val['f1'],\n",
    "        'accuracy':acc_val['accuracy'],\n",
    "    }\n",
    "\n",
    "optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "\n",
    "lr_scheduler = AdafactorSchedule(optimizer)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=5,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\", # run validation at the end of each epoch\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, lr_scheduler)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 11023\n",
      "  Num Epochs = 5\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 865\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='865' max='865' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [865/865 08:53, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.581600</td>\n",
       "      <td>1.534647</td>\n",
       "      <td>0.074824</td>\n",
       "      <td>0.092150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.275700</td>\n",
       "      <td>1.195450</td>\n",
       "      <td>0.295517</td>\n",
       "      <td>0.295506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.923800</td>\n",
       "      <td>0.985746</td>\n",
       "      <td>0.476445</td>\n",
       "      <td>0.465017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.750200</td>\n",
       "      <td>0.969085</td>\n",
       "      <td>0.541806</td>\n",
       "      <td>0.543515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.975895</td>\n",
       "      <td>0.540859</td>\n",
       "      <td>0.541524</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"7.229083621496102e-06\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"1.458576662116684e-05\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"2.194257285736967e-05\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"2.929960101027973e-05\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"3.6657093005487695e-05\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='220' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 00:08]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.975895345211029,\n",
       " 'eval_f1': 0.5408591846213371,\n",
       " 'eval_accuracy': 0.5415244596131968,\n",
       " 'eval_runtime': 8.6548,\n",
       " 'eval_samples_per_second': 406.25,\n",
       " 'eval_steps_per_second': 25.419,\n",
       " 'epoch': 5.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "Using amp half precision backend\n"
     ]
    }
   ],
   "source": [
    "max_layer = 11\n",
    "#max_layer = 24\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    for elem in range(max_layer):\n",
    "        param.requires_grad = True\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    logging_strategy=\"epoch\",\n",
    "    evaluation_strategy=\"epoch\", # run validation at the end of each epoch\n",
    "    save_strategy=\"no\",\n",
    "    fp16=True,\n",
    ")\n",
    "\n",
    "trainer = CustomTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"validation\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    "    optimizers=(optimizer, lr_scheduler)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running training *****\n",
      "  Num examples = 11023\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 346\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='346' max='346' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [346/346 04:05, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.541800</td>\n",
       "      <td>1.120173</td>\n",
       "      <td>0.550459</td>\n",
       "      <td>0.553185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.471500</td>\n",
       "      <td>1.129940</td>\n",
       "      <td>0.539963</td>\n",
       "      <td>0.550057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer is attempting to log a value of \"4.393010385683738e-05\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "Trainer is attempting to log a value of \"5.124660310684703e-05\" of type <class 'torch.Tensor'> for key \"train/learning_rate\" as a scalar. This invocation of Tensorboard's writer.add_scalar() is incorrect so we dropped this attribute.\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "The following columns in the evaluation set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3516\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='600' max='220' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [220/220 04:39]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 1.129940390586853,\n",
       " 'eval_f1': 0.539963188969443,\n",
       " 'eval_accuracy': 0.550056882821388,\n",
       " 'eval_runtime': 8.6836,\n",
       " 'eval_samples_per_second': 404.903,\n",
       " 'eval_steps_per_second': 25.335,\n",
       " 'epoch': 2.0}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: tokens. If tokens are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1507\n",
      "  Batch size = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#ENCODING = {\"label\": {\"Value\": 0, \"Value(+)\": 1, \"Value(-)\": 2, \"Fact\": 3, \"Policy\": 4}}\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions=trainer.predict(test_dataset=tokenized_dataset[\"test\"])\n",
    "preds = np.argmax(predictions.predictions, axis=-1)\n",
    "confusion_matrix = metrics.confusion_matrix(tokenized_dataset['test']['label'], preds, labels=[0,1,2,3,4])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=confusion_matrix,display_labels=[\"Value\",\"Value(+)\",\"Value(-)\",\"Fact\",\"Policy\"])\n",
    "disp.plot()\n",
    "#print(confusion_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n!pip install odfpy\\n!pip install ipywidgets widgetsnbextension pandas-profiling\\n!pip install datasets\\n!pip install transformers\\n!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu110\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "!pip install odfpy\n",
    "!pip install ipywidgets widgetsnbextension pandas-profiling\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu110\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "#!nvidia-smi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
