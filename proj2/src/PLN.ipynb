{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "chunk_size = 128\n",
        "NUM_LABELS = 5\n",
        "\n",
        "model_name = \"neuralmind/bert-large-portuguese-cased\"\n",
        "\n",
        "#model_name = \"turing-usp/FinBertPTBR\"\n",
        "\n",
        "#model_name = \"unicamp-dl/mMiniLM-L6-v2-mmarco-v2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "U0NoEVOTzdlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# data_loading.py"
      ],
      "metadata": {
        "id": "8wDBdneqz5Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "from datasets import Dataset\n",
        "from datasets import DatasetDict\n",
        "\n",
        "ENCODING = {\"label\": {\"Value\": 0, \"Value(+)\": 1, \"Value(-)\": 2, \"Fact\": 3, \"Policy\": 4}}\n",
        "\n",
        "\n",
        "def load_dataset():\n",
        "    \n",
        "    df_text = pd.DataFrame(pd.read_csv(os.path.join('/content','drive','Shareddrives','PLN','dataset', 'OpArticles.csv')))\n",
        "\n",
        "    df_adu = pd.DataFrame(\n",
        "        pd.read_csv(os.path.join('/content','drive','Shareddrives','PLN','dataset', 'OpArticles_ADUs.csv')))\n",
        "\n",
        "    return df_adu, df_text\n",
        "\n",
        "\n",
        "def normalize_dataset(df):\n",
        "    df.drop(columns=['article_id', 'annotator', 'node', 'ranges'], inplace=True)\n",
        "    df.replace(ENCODING, inplace=True)\n",
        "    \n",
        "    #df.rename(columns={'label': 'labels'}, inplace=True)\n",
        "\n",
        "    dataset_hf = Dataset.from_pandas(df)\n",
        "\n",
        "    return dataset_hf\n",
        "\n",
        "\n",
        "def split_train_test(df, test_percentage=0.2, validation_percentage=0.5):\n",
        "    dataset = normalize_dataset(df)\n",
        "\n",
        "    if test_percentage == 1.0:\n",
        "        return DatasetDict({\n",
        "            'test': dataset\n",
        "        })\n",
        "\n",
        "    train_test = dataset.train_test_split(test_size=test_percentage)\n",
        "\n",
        "    # Split the 10% test+validation set in half test, half validation\n",
        "    valid_test = train_test['test'].train_test_split(test_size=(1.0 - validation_percentage))\n",
        "\n",
        "    train_valid_test_dataset = DatasetDict({\n",
        "        'train': train_test['train'],\n",
        "        'validation': valid_test['train'],\n",
        "        'test': valid_test['test']\n",
        "    })\n",
        "\n",
        "    return train_valid_test_dataset\n",
        "\n",
        "\n",
        "def load_data_for_masking(df):\n",
        "    \n",
        "    df.drop(columns=['article_id', 'title', 'authors', 'meta_description', 'topics', 'keywords', 'publish_date',\n",
        "                     'url_canonical'], inplace=True)\n",
        "    \n",
        "    df.rename(columns={'body': 'tokens'}, inplace=True)\n",
        "\n",
        "    dataset = Dataset.from_pandas(df)\n",
        "\n",
        "    train_test = dataset.train_test_split(test_size=0.2)\n",
        "\n",
        "    \n",
        "    train_valid_test_dataset = DatasetDict({\n",
        "        'train': train_test['train'],\n",
        "        'test': train_test['test'],        \n",
        "    })\n",
        "\n",
        "    return train_valid_test_dataset"
      ],
      "metadata": {
        "id": "rbZfgiMnzxin"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"tokens\"], truncation=True, padding=True)\n",
        "\n",
        "def tokenize_function_2(examples):\n",
        "    result = tokenizer(examples[\"tokens\"])\n",
        "    if tokenizer.is_fast:\n",
        "        result[\"word_ids\"] = [result.word_ids(i) for i in range(len(result[\"input_ids\"]))]\n",
        "    return result\n",
        "\n",
        "\n",
        "def group_texts(examples):\n",
        "    # Concatenate all texts\n",
        "    concatenated_examples = {k: sum(examples[k], []) for k in examples.keys()}\n",
        "    # Compute length of concatenated texts\n",
        "    total_length = len(concatenated_examples[list(examples.keys())[0]])\n",
        "    # We drop the last chunk if it's smaller than chunk_size\n",
        "    total_length = (total_length // chunk_size) * chunk_size\n",
        "    # Split by chunks of max_len\n",
        "    result = {\n",
        "        k: [t[i : i + chunk_size] for i in range(0, total_length, chunk_size)]\n",
        "        for k, t in concatenated_examples.items()\n",
        "    }\n",
        "    # Create a new labels column\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result\n",
        "\n",
        "def compute_metrics(eval_preds):\n",
        "    metric = load_metric(\"accuracy\")\n",
        "    logits, labels = eval_preds\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    return metric.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "CVFF2vH7zK_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IFyHtL17ywaX"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding, AutoConfig\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "\n",
        "\n",
        "\n",
        "def task_1(model=None):\n",
        "\n",
        "    df_adu, _ = load_dataset()\n",
        "\n",
        "    dataset = split_train_test(df_adu)\n",
        "    \n",
        "    tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "    \n",
        "    data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "   \n",
        "    training_args = TrainingArguments(\n",
        "            \"test-trainer\", \n",
        "            evaluation_strategy=\"epoch\",\n",
        "            num_train_epochs=10,\n",
        "            #fp16=True,\n",
        "    )\n",
        "    \n",
        "    if model is None:\n",
        "        model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=NUM_LABELS, output_attentions=False, output_hidden_states=False, ignore_mismatched_sizes=True)        \n",
        "    else:\n",
        "        config = AutoConfig.from_pretrained(model_name)\n",
        "        config.num_labels = NUM_LABELS\n",
        "        model = AutoModelForSequenceClassification.from_config(config)\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model,\n",
        "        training_args,\n",
        "        train_dataset=tokenized_datasets[\"train\"],\n",
        "        eval_dataset=tokenized_datasets[\"test\"],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics,\n",
        "        \n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    eval_results = trainer.evaluate()\n",
        "\n",
        "    print(eval_results)\n",
        "    \n",
        "\n",
        "def task_2():\n",
        "    df_adu, df_text=load_dataset()\n",
        "\n",
        "    model = AutoModelForMaskedLM.from_pretrained(model_name)\n",
        "    \n",
        "    dataset = load_data_for_masking(df_text)\n",
        "\n",
        "    tokenized_datasets = dataset.map(\n",
        "        tokenize_function_2, batched=True, remove_columns=[\"tokens\"]\n",
        "    )\n",
        "\n",
        "\n",
        "    lm_datasets = tokenized_datasets.map(group_texts, batched=True)\n",
        "\n",
        "    data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=0.15)\n",
        "\n",
        "\n",
        "    #batch_size = 64\n",
        "    # Show the training loss with every epoch\n",
        "    #logging_steps = len(lm_datasets[\"train\"]) // batch_size\n",
        "\n",
        "    training_args = TrainingArguments(\n",
        "        output_dir=f\"{model_name}-finetuned-imdb\",        \n",
        "        evaluation_strategy=\"epoch\",\n",
        "        num_train_epochs=5,\n",
        "        #fp16=True,\n",
        "    )\n",
        "\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=lm_datasets[\"train\"],\n",
        "        eval_dataset=lm_datasets[\"test\"],\n",
        "        data_collator=data_collator,\n",
        "    )\n",
        "\n",
        "\n",
        "    #eval_results = trainer.evaluate()\n",
        "    #print(f\">>> Perplexity Before: {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    #eval_results = trainer.evaluate()\n",
        "    #print(f\">>> Perplexity After: {math.exp(eval_results['eval_loss']):.2f}\")\n",
        "\n",
        "    task_1(model)\n",
        "\n",
        "\n",
        "task_1()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PaBpsCVG1GI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qOGh9bmh1POs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\"\"\"\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "9IEoByX21bSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "20Y2TG5F1pJe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}